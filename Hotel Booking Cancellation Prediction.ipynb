{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2a9d5e40-cd3e-401d-bf5d-ad5af8191001",
   "metadata": {},
   "source": [
    "# hotel_cancellation.py\n",
    "# End-to-end pipeline: Hotel Booking Cancellation Prediction\n",
    "# Author: Arif Farhan Bukhori (Hans)\n",
    "# -----------------------------------------------------------\n",
    "# Features:\n",
    "# - Loads & cleans INN Hotels data\n",
    "# - EDA (distribution plots, correlations, segment price boxplots)\n",
    "# - Modeling: Logistic Regression, SVM (Linear & RBF), Decision Tree (tuned), Random Forest\n",
    "# - Threshold tuning via Precision-Recall curves\n",
    "# - Confusion matrices, classification reports, feature importance\n",
    "# - Saves plots to ./visuals and best models to ./models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002c57ec-9971-44b9-9210-e98c709fbe64",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6301a5-f65a-4a40-8596-c7030ae3817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06173897-84fb-4dd5-b017-7f35b192a69b",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13a1809-e87f-46e3-a98a-4acae309abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dirs():\n",
    "    Path(\"visuals\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(\"models\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_cm(cm: np.ndarray, labels: Tuple[str, str], title: str, fname: str):\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='.0f',\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    plt.ylabel('Actual'); plt.xlabel('Predicted'); plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fname, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "def plot_pr_threshold(y_true: pd.Series, y_scores: np.ndarray, title: str, fname: str):\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "    # thresholds has len-1 compared to prec/rec\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(thresholds, precisions[:-1], label='Precision', linestyle='--')\n",
    "    plt.plot(thresholds, recalls[:-1], label='Recall', linestyle='--')\n",
    "    plt.xlabel('Threshold'); plt.ylim(0, 1.0); plt.legend(); plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fname, dpi=150); plt.close()\n",
    "    # Return threshold that maximizes F1\n",
    "    f1s = 2 * (precisions * recalls) / (precisions + recalls + 1e-12)\n",
    "    best_idx = np.nanargmax(f1s)\n",
    "    best_thr = 0.5 if best_idx == len(thresholds) else (thresholds[best_idx-1] if best_idx>0 else thresholds[0])\n",
    "    return best_thr, precisions[best_idx], recalls[best_idx], f1s[best_idx]\n",
    "\n",
    "def metrics_score(y_true, y_pred, title_prefix: str, tag: str) -> Dict[str, float]:\n",
    "    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "    printable = classification_report(y_true, y_pred, zero_division=0)\n",
    "    print(f\"\\n{title_prefix} Classification Report:\\n{printable}\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    save_cm(cm, labels=('Not Cancelled','Cancelled'),\n",
    "            title=f\"{title_prefix} — Confusion Matrix\",\n",
    "            fname=f\"visuals/cm_{tag}.png\")\n",
    "    # Return class-1 (Cancelled) metrics and accuracy\n",
    "    return {\n",
    "        \"accuracy\": report[\"accuracy\"],\n",
    "        \"precision_cancel\": report[\"1\"][\"precision\"],\n",
    "        \"recall_cancel\": report[\"1\"][\"recall\"],\n",
    "        \"f1_cancel\": report[\"1\"][\"f1-score\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9be259-8578-468f-9b6d-5d11e1ae778b",
   "metadata": {},
   "source": [
    "# Data Loading & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff353da2-3a3b-4b63-b610-9c66182892ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return df.copy()\n",
    "\n",
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Drop ID\n",
    "    if \"Booking_ID\" in df.columns:\n",
    "        df = df.drop(columns=[\"Booking_ID\"])\n",
    "\n",
    "    # Fix unrealistic children values (replace 9,10 with 3)\n",
    "    if \"no_of_children\" in df.columns:\n",
    "        df[\"no_of_children\"] = df[\"no_of_children\"].replace([9,10], 3)\n",
    "\n",
    "    # Encode target: Canceled=1, Not_Canceled=0\n",
    "    if \"booking_status\" in df.columns and df[\"booking_status\"].dtype == object:\n",
    "        df[\"booking_status\"] = df[\"booking_status\"].apply(lambda x: 1 if x == \"Canceled\" else 0)\n",
    "\n",
    "    # Cap extreme outliers for avg_price_per_room at upper whisker (exclude zeros)\n",
    "    if \"avg_price_per_room\" in df.columns:\n",
    "        Q1 = df[\"avg_price_per_room\"].quantile(0.25)\n",
    "        Q3 = df[\"avg_price_per_room\"].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        upper = Q3 + 1.5*IQR\n",
    "        df.loc[df[\"avg_price_per_room\"] >= 500, \"avg_price_per_room\"] = upper\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b93a07-88d6-43f9-9950-bc10130034e3",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0067e264-7e22-4075-bf11-71f17a1594f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda_plots(df: pd.DataFrame, enable: bool = True):\n",
    "    if not enable:\n",
    "        return\n",
    "\n",
    "    # Distributions\n",
    "    for col in [\"lead_time\", \"avg_price_per_room\", \"no_of_week_nights\", \"no_of_weekend_nights\"]:\n",
    "        if col in df.columns:\n",
    "            plt.figure(figsize=(6,4))\n",
    "            sns.boxplot(x=df[col])\n",
    "            plt.title(f\"Boxplot — {col}\")\n",
    "            plt.tight_layout(); plt.savefig(f\"visuals/box_{col}.png\", dpi=150); plt.close()\n",
    "\n",
    "            plt.figure(figsize=(6,4))\n",
    "            sns.histplot(df[col], kde=True, bins=30)\n",
    "            plt.title(f\"Histogram — {col}\")\n",
    "            plt.tight_layout(); plt.savefig(f\"visuals/hist_{col}.png\", dpi=150); plt.close()\n",
    "\n",
    "    # Booking status distribution\n",
    "    if \"booking_status\" in df.columns:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        sns.countplot(x=df[\"booking_status\"].map({0:\"Not_Canceled\",1:\"Canceled\"}))\n",
    "        plt.title(\"Target distribution — booking_status\")\n",
    "        plt.tight_layout(); plt.savefig(\"visuals/target_distribution.png\", dpi=150); plt.close()\n",
    "\n",
    "    # Correlation heatmap (numeric only)\n",
    "    num_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "    plt.figure(figsize=(10,7))\n",
    "    sns.heatmap(df[num_cols].corr(), annot=False, cmap=\"Spectral\", vmin=-1, vmax=1)\n",
    "    plt.title(\"Correlation Heatmap (numeric)\")\n",
    "    plt.tight_layout(); plt.savefig(\"visuals/corr_heatmap.png\", dpi=150); plt.close()\n",
    "\n",
    "    # Avg price per room by market segment (if exists)\n",
    "    if \"market_segment_type\" in df.columns and \"avg_price_per_room\" in df.columns:\n",
    "        plt.figure(figsize=(8,5))\n",
    "        sns.boxplot(data=df, x=\"market_segment_type\", y=\"avg_price_per_room\")\n",
    "        plt.xticks(rotation=30, ha='right')\n",
    "        plt.title(\"Avg Price per Room by Market Segment\")\n",
    "        plt.tight_layout(); plt.savefig(\"visuals/price_by_segment.png\", dpi=150); plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326ffa21-c37c-4d78-8f32-5197ce3da588",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645a372f-fc7c-4077-8330-efacb8663248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Modeling\n",
    "# ==========================\n",
    "\n",
    "def split_encode(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series, pd.DataFrame, pd.Series]:\n",
    "    X = df.drop(columns=[\"booking_status\"])\n",
    "    y = df[\"booking_status\"]\n",
    "    X = pd.get_dummies(X, drop_first=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.30, stratify=y, random_state=1\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_logistic(X_train, y_train):\n",
    "    lg = LogisticRegression(max_iter=200)\n",
    "    lg.fit(X_train, y_train)\n",
    "    joblib.dump(lg, \"models/logistic_regression.joblib\")\n",
    "    return lg\n",
    "\n",
    "def train_svm_linear(X_train, y_train):\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    Xs = scaler.fit_transform(X_train)\n",
    "    svm = SVC(kernel=\"linear\", probability=True, random_state=1)\n",
    "    svm.fit(Xs, y_train)\n",
    "    joblib.dump(scaler, \"models/scaler_svm_linear.joblib\")\n",
    "    joblib.dump(svm, \"models/svm_linear.joblib\")\n",
    "    return svm, scaler\n",
    "\n",
    "def train_svm_rbf(X_train, y_train):\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    Xs = scaler.fit_transform(X_train)\n",
    "    svm = SVC(kernel=\"rbf\", probability=True, random_state=1)\n",
    "    svm.fit(Xs, y_train)\n",
    "    joblib.dump(scaler, \"models/scaler_svm_rbf.joblib\")\n",
    "    joblib.dump(svm, \"models/svm_rbf.joblib\")\n",
    "    return svm, scaler\n",
    "\n",
    "def train_decision_tree_tuned(X_train, y_train):\n",
    "    base = DecisionTreeClassifier(random_state=1)\n",
    "    params = {\n",
    "        \"max_depth\": np.arange(1, 100, 10),\n",
    "        \"max_leaf_nodes\": [50, 75, 150, 250],\n",
    "        \"min_samples_split\": [10, 30, 50, 70],\n",
    "    }\n",
    "    gs = GridSearchCV(base, params, cv=5, scoring=\"recall\", n_jobs=-1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    best = gs.best_estimator_\n",
    "    joblib.dump(best, \"models/decision_tree_tuned.joblib\")\n",
    "    return best\n",
    "\n",
    "def train_random_forest(X_train, y_train):\n",
    "    rf = RandomForestClassifier(random_state=1, n_estimators=300, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    joblib.dump(rf, \"models/random_forest.joblib\")\n",
    "    return rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c137a3-5098-4c03-a436-39e41f758be8",
   "metadata": {},
   "source": [
    "# Run & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64323b32-3065-4146-8a9b-58004a758a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(csv_path: str, run_eda: bool):\n",
    "    ensure_dirs()\n",
    "\n",
    "    print(\"Loading data...\")\n",
    "    df = load_data(csv_path)\n",
    "    print(f\"Initial shape: {df.shape}\")\n",
    "\n",
    "    print(\"Cleaning data...\")\n",
    "    df = clean_data(df)\n",
    "    print(f\"Post-clean shape: {df.shape}\")\n",
    "\n",
    "    if run_eda:\n",
    "        print(\"Generating EDA visuals...\")\n",
    "        eda_plots(df, enable=True)\n",
    "\n",
    "    print(\"Encoding & splitting...\")\n",
    "    X_train, X_test, y_train, y_test = split_encode(df)\n",
    "    print(f\"Train shape: {X_train.shape} | Test shape: {X_test.shape}\")\n",
    "    print(\"Target ratio (train):\", y_train.value_counts(normalize=True).to_dict())\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # 1) Logistic Regression\n",
    "    print(\"\\n=== Logistic Regression ===\")\n",
    "    lg = train_logistic(X_train, y_train)\n",
    "    y_hat_tr = lg.predict(X_train)\n",
    "    r_tr = metrics_score(y_train, y_hat_tr, \"LR — Train\", \"lr_train\")\n",
    "    y_hat_te = lg.predict(X_test)\n",
    "    r_te = metrics_score(y_test, y_hat_te, \"LR — Test\", \"lr_test\")\n",
    "\n",
    "    # Threshold tuning (LR)\n",
    "    y_scores_tr = lg.predict_proba(X_train)[:,1]\n",
    "    thr, p_opt, r_opt, f1_opt = plot_pr_threshold(\n",
    "        y_train, y_scores_tr, \"LR — Precision/Recall vs Threshold\", \"visuals/pr_lr.png\"\n",
    "    )\n",
    "    # Use 0.40 as course reference but also show best-f1 threshold\n",
    "    custom_thr = 0.40\n",
    "    y_hat_thr_tr = (lg.predict_proba(X_train)[:,1] > custom_thr).astype(int)\n",
    "    y_hat_thr_te = (lg.predict_proba(X_test)[:,1] > custom_thr).astype(int)\n",
    "    r_thr_tr = metrics_score(y_train, y_hat_thr_tr, f\"LR@{custom_thr:.2f} — Train\", \"lr_thr_train\")\n",
    "    r_thr_te = metrics_score(y_test, y_hat_thr_te, f\"LR@{custom_thr:.2f} — Test\", \"lr_thr_test\")\n",
    "\n",
    "    results.append((\"Logistic Regression\", r_te))\n",
    "\n",
    "    # 2) SVM Linear\n",
    "    print(\"\\n=== SVM (Linear) ===\")\n",
    "    svm_lin, scaler_lin = train_svm_linear(X_train, y_train)\n",
    "    Xtr_s = scaler_lin.transform(X_train)\n",
    "    Xte_s = scaler_lin.transform(X_test)\n",
    "    r_tr = metrics_score(y_train, svm_lin.predict(Xtr_s), \"SVM-Linear — Train\", \"svml_train\")\n",
    "    r_te = metrics_score(y_test, svm_lin.predict(Xte_s), \"SVM-Linear — Test\", \"svml_test\")\n",
    "\n",
    "    # Threshold tuning (SVM Linear)\n",
    "    thr_lin, _, _, _ = plot_pr_threshold(\n",
    "        y_train, svm_lin.predict_proba(Xtr_s)[:,1], \"SVM-Linear — Precision/Recall vs Threshold\", \"visuals/pr_svml.png\"\n",
    "    )\n",
    "    custom_thr = 0.40\n",
    "    r_thr_tr = metrics_score(y_train, (svm_lin.predict_proba(Xtr_s)[:,1] > custom_thr).astype(int),\n",
    "                             f\"SVM-Linear@{custom_thr:.2f} — Train\", \"svml_thr_train\")\n",
    "    r_thr_te = metrics_score(y_test, (svm_lin.predict_proba(Xte_s)[:,1] > custom_thr).astype(int),\n",
    "                             f\"SVM-Linear@{custom_thr:.2f} — Test\", \"svml_thr_test\")\n",
    "\n",
    "    results.append((\"SVM (Linear)\", r_te))\n",
    "\n",
    "    # 3) SVM RBF\n",
    "    print(\"\\n=== SVM (RBF) ===\")\n",
    "    svm_rbf, scaler_rbf = train_svm_rbf(X_train, y_train)\n",
    "    Xtr_s = scaler_rbf.transform(X_train)\n",
    "    Xte_s = scaler_rbf.transform(X_test)\n",
    "    r_tr = metrics_score(y_train, svm_rbf.predict(Xtr_s), \"SVM-RBF — Train\", \"svmr_train\")\n",
    "    r_te = metrics_score(y_test, svm_rbf.predict(Xte_s), \"SVM-RBF — Test\", \"svmr_test\")\n",
    "\n",
    "    thr_rbf, _, _, _ = plot_pr_threshold(\n",
    "        y_train, svm_rbf.predict_proba(Xtr_s)[:,1], \"SVM-RBF — Precision/Recall vs Threshold\", \"visuals/pr_svmr.png\"\n",
    "    )\n",
    "    custom_thr = 0.40\n",
    "    r_thr_tr = metrics_score(y_train, (svm_rbf.predict_proba(Xtr_s)[:,1] > custom_thr).astype(int),\n",
    "                             f\"SVM-RBF@{custom_thr:.2f} — Train\", \"svmr_thr_train\")\n",
    "    r_thr_te = metrics_score(y_test, (svm_rbf.predict_proba(Xte_s)[:,1] > custom_thr).astype(int),\n",
    "                             f\"SVM-RBF@{custom_thr:.2f} — Test\", \"svmr_thr_test\")\n",
    "\n",
    "    results.append((\"SVM (RBF)\", r_te))\n",
    "\n",
    "    # 4) Decision Tree (tuned)\n",
    "    print(\"\\n=== Decision Tree (Tuned) ===\")\n",
    "    dt = train_decision_tree_tuned(X_train, y_train)\n",
    "    r_tr = metrics_score(y_train, dt.predict(X_train), \"DT-Tuned — Train\", \"dt_train\")\n",
    "    r_te = metrics_score(y_test, dt.predict(X_test), \"DT-Tuned — Test\", \"dt_test\")\n",
    "\n",
    "    # Export shallow tree viz\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plot_tree(dt, feature_names=X_train.columns, max_depth=3, filled=True, fontsize=8)\n",
    "    plt.tight_layout(); plt.savefig(\"visuals/decision_tree_top.png\", dpi=200); plt.close()\n",
    "\n",
    "    # Feature importance DT\n",
    "    importances = pd.Series(dt.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "    plt.figure(figsize=(8,10))\n",
    "    sns.barplot(x=importances.head(20), y=importances.head(20).index)\n",
    "    plt.title(\"Decision Tree — Top 20 Feature Importances\")\n",
    "    plt.tight_layout(); plt.savefig(\"visuals/dt_feature_importance.png\", dpi=150); plt.close()\n",
    "\n",
    "    results.append((\"Decision Tree (Tuned)\", r_te))\n",
    "\n",
    "    # 5) Random Forest\n",
    "    print(\"\\n=== Random Forest ===\")\n",
    "    rf = train_random_forest(X_train, y_train)\n",
    "    r_tr = metrics_score(y_train, rf.predict(X_train), \"RF — Train\", \"rf_train\")\n",
    "    r_te = metrics_score(y_test, rf.predict(X_test), \"RF — Test\", \"rf_test\")\n",
    "\n",
    "    rf_imp = pd.Series(rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "    plt.figure(figsize=(8,10))\n",
    "    sns.barplot(x=rf_imp.head(20), y=rf_imp.head(20).index)\n",
    "    plt.title(\"Random Forest — Top 20 Feature Importances\")\n",
    "    plt.tight_layout(); plt.savefig(\"visuals/rf_feature_importance.png\", dpi=150); plt.close()\n",
    "\n",
    "    results.append((\"Random Forest\", r_te))\n",
    "\n",
    "    # Save summary table\n",
    "    summary = pd.DataFrame(\n",
    "        [(name, r[\"accuracy\"], r[\"precision_cancel\"], r[\"recall_cancel\"], r[\"f1_cancel\"])\n",
    "         for name, r in results],\n",
    "        columns=[\"Model\",\"Accuracy\",\"Precision (Cancel)\",\"Recall (Cancel)\",\"F1 (Cancel)\"]\n",
    "    ).sort_values(by=[\"F1 (Cancel)\",\"Recall (Cancel)\",\"Accuracy\"], ascending=False)\n",
    "    print(\"\\n=== Test Set Summary ===\")\n",
    "    print(summary.to_string(index=False))\n",
    "    summary.to_csv(\"visuals/model_summary.csv\", index=False)\n",
    "\n",
    "    print(\"\\nArtifacts saved to ./visuals and ./models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81734fb-713b-49ea-b110-3c84f297cb1a",
   "metadata": {},
   "source": [
    "# Entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38059814-572a-44fb-8394-19a326bd5388",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Hotel Booking Cancellation Prediction Pipeline\")\n",
    "    parser.add_argument(\"--csv\", type=str, default=\"data/INNHotelsGroup.csv\",\n",
    "                        help=\"Path to INN Hotels CSV file\")\n",
    "    parser.add_argument(\"--eda\", action=\"store_true\", help=\"Generate EDA plots\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # (Optional) Google Colab Drive mount\n",
    "    # from google.colab import drive\n",
    "    # drive.mount('/content/drive')\n",
    "    # csv_path = \"/content/drive/MyDrive/MIT: DSML/Hotel Booking Cancellation Prediction/INNHotelsGroup.csv\"\n",
    "\n",
    "    run_pipeline(args.csv, run_eda=args.eda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
